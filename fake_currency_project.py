# -*- coding: utf-8 -*-
"""fake currency project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l5UieceuUsBKhyyy1qiOkfvIDAw_b6ZW
"""

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Conv2D

import numpy as np
from glob import glob

import os
from google.colab import drive

drive.mount('/content/drive')

# re-size all the images to this
IMAGE_SIZE = [224, 224]


# Assuming your dataset is directly in the specified folder on your Google Drive
train_path = '/content/drive/MyDrive/dataSet/Train'
valid_path = '/content/drive/MyDrive/dataSet/Test'

# Verify the directories exist
if not os.path.exists(train_path):
  print(f"Error: Training directory not found at {train_path}")
if not os.path.exists(valid_path):
  print(f"Error: Validation directory not found at {valid_path}")

# useful for getting number of output classes
folders = glob('/content/drive/MyDrive/dataSet/Train/*')

folders

import matplotlib.image as mpimg
from glob import glob
import os
import matplotlib.pyplot as plt
train_image_files = glob(os.path.join(train_path, '*/*.jpg'))

# Display some sample images from the training directory
num_images_to_display = 5
for img_path in train_image_files[:num_images_to_display]:
    img = mpimg.imread(img_path)
    plt.imshow(img)
    plt.axis('off')
    plt.show()

import os
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet import MobileNet
from tensorflow.keras.applications.mobilenet import preprocess_input
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
train_set = datagen.flow_from_directory(train_path, target_size=(IMAGE_SIZE[0], IMAGE_SIZE[1]), batch_size=32, class_mode='categorical')
valid_set = datagen.flow_from_directory(valid_path, target_size=(IMAGE_SIZE[0], IMAGE_SIZE[1]), batch_size=32, class_mode='categorical')

# Load MobileNet model with pre-trained weights, excluding the top (fully connected) layers
base_model = MobileNet(weights='imagenet', include_top=False)

# Add custom top layers for classification
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
x = Dense(1024, activation='relu')(x)
x = Dense(512, activation='relu')(x)
preds = Dense(len(folders), activation='softmax')(x)  # Assuming one node for each class

# Create the model
model = Model(inputs=base_model.input, outputs=preds)

# Compile the model
# Changed 'lr' to 'learning_rate'
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
hist=model.fit(train_set, validation_data=valid_set, epochs=10, steps_per_epoch=len(train_set), validation_steps=len(valid_set))

import matplotlib.pyplot as plt
plt.plot(hist.history['accuracy'], label='Training Accuracy')
plt.plot(hist.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

model.save("fake_currrecy_detection.h5")

# Load the saved model
import tensorflow as tf
loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/dataSet/fake_currrecy_detection.h5')

test_image_path = '/content/drive/MyDrive/dataSet/Test/1Hundrednote/1.jpg'  # Change this to the path of your test image

# Load the test image
test_img = image.load_img(test_image_path, target_size=IMAGE_SIZE)
test_img_array = image.img_to_array(test_img)
test_img_array = np.expand_dims(test_img_array, axis=0)  # Add batch dimension

# Normalize the image data
test_img_array = test_img_array / 255.0

# Make prediction
predictions = loaded_model.predict(test_img_array)

# Class labels
class_labels = ['Fake', 'Real']

# Get the predicted class label
predicted_class_index = np.argmax(predictions[0])
predicted_class_label = class_labels[predicted_class_index]

print("Predicted class:", predicted_class_label)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam
# Assuming you have already defined 'folders' earlier using glob
num_classes = len(folders) # Get the number of classes from your earlier definition

# Define the CNN model for multi-class classification
model = Sequential([
    Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    #Conv2D(128, (3, 3), activation='relu'),
    #MaxPooling2D((2, 2)),
    Flatten(),
    Dense(120, activation='relu'),
    # Changed the output layer for multi-class classification
    Dense(num_classes, activation='softmax') # Output layer with 'num_classes' nodes and softmax activation
])

# Compile the model
# Changed loss function for multi-class classification
model.compile(optimizer='adam',
              loss='categorical_crossentropy', # Use categorical_crossentropy for multi-class
              metrics=['accuracy'])

# Display model summary
model.summary()

# Train the model
# This should now work with the existing multi-class train_set and valid_set
history = model.fit(train_set, epochs=5, validation_data=valid_set)

# Save the trained model
model.save("cnn_model.h5")

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D

# Load the pre-trained ResNet50 model
base_model = ResNet50(weights='imagenet', include_top=False)

# Add custom classification layers on top
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
# Changed the output layer for multi-class classification
# Use 'num_classes' (which should be 7) and 'softmax' activation
# Assuming 'folders' and thus 'num_classes' are defined earlier
num_classes = len(folders) # Ensure num_classes is defined, though it likely is from earlier cells
predictions = Dense(num_classes, activation='softmax')(x)

# Combine the base model with custom classification layers
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer='adam',
              # Changed loss function for multi-class classification
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(train_set, epochs=5, validation_data=valid_set)

# Save the trained model
model.save("resnet_model.h5")

import seaborn as sns
import matplotlib.pyplot as plt

# Extract accuracies from the training history of each model
mobile_acc = hist.history['accuracy'][-1]  # Taking the final accuracy value
cnn_acc = history.history['accuracy'][-1]  # Taking the final accuracy value
resnet_acc = history.history['accuracy'][-1]  # Taking the final accuracy value

# Create a DataFrame
data = {
    'Model': ['Proposed_model', 'CNN', 'ResNet50'],
    'Accuracy': [mobile_acc, cnn_acc, resnet_acc]
}

# Create a bar plot using Seaborn
plt.figure(figsize=(10, 9))  # Increase plot size
sns.barplot(x='Model', y='Accuracy', data=data)

# Add title and labels
plt.title('Comparison of Model Accuracies')
plt.xlabel('Model')
plt.ylabel('Accuracy')


plt.show()

import os
from google.colab import drive

drive.mount('/content/drive')

# Load the saved model
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import numpy as np
from glob import glob
IMAGE_SIZE = [224, 224]

loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/dataSet/fake_currrecy_detection.h5')

test_image_path = '/content/drive/MyDrive/dataSet/Test/1Hundrednote/1.jpg'  # Change this to the path of your test image


# Load the test image
test_img = image.load_img(test_image_path, target_size=IMAGE_SIZE)
test_img_array = image.img_to_array(test_img)
test_img_array = np.expand_dims(test_img_array, axis=0)  # Add batch dimension

# Normalize the image data
test_img_array = test_img_array / 255.0

# Make prediction
predictions = loaded_model.predict(test_img_array)

# Class labels
class_labels = ['Fake', 'Real']

# Get the predicted class label
predicted_class_index = np.argmax(predictions[0])
predicted_class_label = class_labels[predicted_class_index]

print("Predicted class:", predicted_class_label)

